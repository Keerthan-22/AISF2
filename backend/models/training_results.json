{
  "timestamp": "2025-07-28T14:24:56.133261",
  "models_trained": [
    "threat_classifier",
    "gmm_detector",
    "autoencoder_detector",
    "sequential_analyzer",
    "response_optimizer"
  ],
  "overall_accuracy": 0.7344747075441136,
  "training_duration": 505.64904,
  "threat_classifier": {
    "accuracy": 0.605,
    "cv_mean": 0.6112500000000001,
    "cv_std": 0.0025000000000000356,
    "classification_report": "              precision    recall  f1-score   support\n\n         dos       0.00      0.00      0.00        38\n      normal       0.61      0.98      0.75       123\n       probe       0.00      0.00      0.00        29\n         r2l       0.00      0.00      0.00         9\n         u2r       0.00      0.00      0.00         1\n\n    accuracy                           0.60       200\n   macro avg       0.12      0.20      0.15       200\nweighted avg       0.38      0.60      0.46       200\n",
    "confusion_matrix": "[[  0  38   0   0   0]\n [  2 121   0   0   0]\n [  0  29   0   0   0]\n [  0   9   0   0   0]\n [  0   1   0   0   0]]",
    "model_type": "Random Forest",
    "target_accuracy": 0.9769,
    "accuracy_gap": 0.3719
  },
  "gmm_detector": {
    "silhouette_score": 0.17701790018292554,
    "n_components": 3,
    "threshold": -13.221093734042697,
    "mean_log_likelihood": -4.005088799552372,
    "model_type": "Gaussian Mixture Model"
  },
  "autoencoder_detector": {
    "error": "Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=models/autoencoder."
  },
  "sequential_analyzer": {
    "test_accuracy": 0.9989898800849915,
    "test_loss": 0.009572219103574753,
    "final_accuracy": 0.9972222447395325,
    "final_val_accuracy": 0.9989898800849915,
    "model_type": "LSTM",
    "sequence_length": 50
  },
  "response_optimizer": {
    "episodes_trained": 500,
    "average_reward": 0.7454,
    "final_reward": 0.75,
    "model_type": "PPO (Proximal Policy Optimization)",
    "state_dim": 20,
    "action_dim": 8
  }
}